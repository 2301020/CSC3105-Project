{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2301020/CSC3105-Project/blob/main/UoG-DA_Group28.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxa3tmd0qUbU"
      },
      "source": [
        "# UoG-DA_Group28 Jupyter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoTv1anyqUbX"
      },
      "source": [
        "## <u> Data Pre-Processing </u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "xRGA8j1HqUbX",
        "outputId": "385dd3ac-3389-406f-95bd-eb60673d2d36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'UWB_LOS_NLOS_Data_Set'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4abb2dabba18>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mUWB_LOS_NLOS_Data_Set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muwb_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Method to extract data from all 7 files to a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'UWB_LOS_NLOS_Data_Set'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from UWB_LOS_NLOS_Data_Set.code.uwb_dataset import *\n",
        "\n",
        "# Method to extract data from all 7 files to a Pandas DataFrame\n",
        "def import_from_files_single_dataframe(rootdir):\n",
        "    file_list =[]\n",
        "    for dirpath, dirnames, filenames in os.walk(rootdir):\n",
        "        for file in filenames:\n",
        "            filename = os.path.join(dirpath, file)\n",
        "            print(filename)\n",
        "            file_list.append(filename)\n",
        "            # read data from file\n",
        "\n",
        "    df = pd.concat((pd.read_csv(f) for f in file_list), ignore_index=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK7MvXqzqUbY"
      },
      "outputs": [],
      "source": [
        "# Import raw data from folder with dataset\n",
        "print(\"Importing dataset to Pandas dataframe\")\n",
        "print(\"-------------------------------\")\n",
        "data = import_from_files_single_dataframe(\"./UWB_LOS_NLOS_Data_Set/dataset/\")\n",
        "\n",
        "print(\"\\nDataset:\")\n",
        "print(\"-------------------------------\")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ_Hfzo1qUbZ"
      },
      "outputs": [],
      "source": [
        "# Check if where are any nulls or missing values in dataset\n",
        "\n",
        "print(\"\\nAre Nulls detected in dataframe: \", data.isnull().values.any())\n",
        "\n",
        "print(\"\\nNumber of Nulls detected in dataframe by attribute:\")\n",
        "print(\"-------------------------------\")\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJSm0raKqUba"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(data)\n",
        "projected = pca.transform(data)\n",
        "projected_1 = pd.DataFrame(projected,index=range(1,data.shape[0]+1))\n",
        "\n",
        "projected_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZDsJpfeqUba"
      },
      "outputs": [],
      "source": [
        "# calculate cumulative sum of explained variances\n",
        "tot = sum(pca.explained_variance_)\n",
        "print(pca.explained_variance_)\n",
        "print(tot)\n",
        "var_exp = [(i/tot ) for i in sorted(pca.explained_variance_, reverse=True)]\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "pc_count = len(var_exp)\n",
        "print(pc_count)\n",
        "# plot explained variances\n",
        "plt.bar(range(1,pc_count+1), var_exp, alpha=0.5,\n",
        "        align='center', label='individual explained variance')\n",
        "plt.step(range(1,pc_count+1), cum_var_exp, where='mid',\n",
        "         label='cumulative explained variance')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.xlabel('Principal component index')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JyJct6wqUbb"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBkYdfm7qUbc"
      },
      "source": [
        "## <u> Data Mining </u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUIXhB5DqUbc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xgiZFVbqUbd"
      },
      "source": [
        "## <u> Data Post-Processing </u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKW2WmujqUbd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}